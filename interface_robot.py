import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import IsolationForest
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.model_selection import train_test_split
from io import StringIO
import sys


# =============================================================================
# FONCTIONS UTILITAIRES DE MACHINE LEARNING
# =============================================================================

@st.cache_data
def load_data(file_path="Robot.csv"):
    """Charge les donn√©es √† partir du fichier CSV."""
    try:
        df = pd.read_csv(file_path)
        return df
    except FileNotFoundError:
        st.error(f"Erreur fatale : Le fichier '{file_path}' est introuvable.")
        st.stop()
        return None


@st.cache_data(show_spinner="Entra√Ænement de l'Isolation Forest...")
def train_isolation_forest(X, contamination):
    """Entra√Æne et pr√©dit avec l'Isolation Forest."""
    model = IsolationForest(contamination=contamination, random_state=42)
    model.fit(X)
    pred = model.predict(X)
    return model, pred


@st.cache_data(show_spinner="Entra√Ænement de l'Arbre de D√©cision...")
def train_decision_tree(X, y):
    """Entra√Æne et retourne le mod√®le Decision Tree."""
    # S√©paration des donn√©es (70% train / 30% test)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )

    # Entra√Ænement
    tree = DecisionTreeClassifier(max_depth=None, random_state=0)
    tree.fit(X_train, y_train)

    return tree, X_train, X_test, y_train, y_test


# =============================================================================
# FONCTIONS DE SECTIONS (pour les Onglets)
# =============================================================================

def section_exploration(df):
    """Contient toutes les informations pour la section 1 : Exploration des Donn√©es."""

    # Calculs pr√©liminaires
    defaillance_count = df["Cycle_Normal"].value_counts()
    normal_cycles = defaillance_count.get(1, 0)
    failed_cycles = defaillance_count.get(0, 0)
    total_rows = len(df)

    st.markdown("### Aper√ßu des Donn√©es et Statistiques Cl√©s")

    col1, col2 = st.columns([3, 2])

    with col1:
        st.subheader("Aper√ßu de toutes les Donn√©es disponibles")
        st.dataframe(df)  # Affiche tout le DataFrame sans limitation

    with col2:
        st.subheader("R√©partition des Cycles")

        st.metric(label="Cycles Normaux (Cycle_Normal = 1)", value=normal_cycles)
        st.metric(label="Cycles D√©faillants (Cycle_Normal = 0)", value=failed_cycles)

        st.markdown("---")
        st.metric(label="Dimensions du Dataset", value=f"{df.shape[0]} lignes, {df.shape[1]} colonnes")

        if total_rows > 0:
            pct_defaillance = (failed_cycles / total_rows * 100)
            st.metric(label="Pourcentage de D√©faillances", value=f"{pct_defaillance:.2f}%")

    # Visualisation Pairplot
    st.markdown("### Visualisation - Pairplot des Caract√©ristiques")
    with st.expander("Cliquez ici pour visualiser le Pairplot complet (peut prendre quelques secondes)"):
        st.write("G√©n√©ration du Pairplot... (Cycles normaux en vert, D√©faillances en rouge)")
        try:
            # Cr√©ation de la figure Pairplot
            fig_pair = sns.pairplot(df, hue="Cycle_Normal", palette={1: "green", 0: "red"})
            st.pyplot(fig_pair)
        except Exception as e:
            st.warning(f"Impossible de g√©n√©rer le Pairplot : {e}")

    st.markdown("---")


def section_isolation_forest(df):
    """Contient toutes les informations pour la section 2 : Isolation Forest."""

    st.markdown("### Apprentissage Non Supervis√© : D√©tection d'Anomalies")
    st.markdown(
        "L'algorithme apprend √† distinguer les cycles d√©faillants sans utiliser l'√©tiquette initiale (`Cycle_Normal`).")

    # Pr√©pare les donn√©es pour la for√™t d'isolation
    X = df.iloc[:, :-1].copy()
    total_rows = len(df)
    failed_cycles = df["Cycle_Normal"].value_counts().get(0, 0)
    real_contamination = failed_cycles / total_rows

    # -------------------------------------------------------------------------
    # CURSEUR INTERACTIF
    # -------------------------------------------------------------------------
    contamination_rate = st.slider(
        "Taux de contamination estim√© (Isolation Forest)",
        min_value=0.01, max_value=0.05,
        value=min(0.02, 0.05),  # Valeur par d√©faut 2%
        step=0.005,
        format='%.3f',
        help=f"Ce param√®tre indique au mod√®le le pourcentage d'anomalies √† rechercher. Taux r√©el : {real_contamination * 100:.2f}%."
    )

    # -------------------------------------------------------------------------
    # EX√âCUTION & R√âSULTATS
    # -------------------------------------------------------------------------

    st.subheader(f"R√©sultats pour Contamination = {contamination_rate * 100:.2f}%")

    model, pred = train_isolation_forest(X, contamination_rate)

    temp = pd.DataFrame({'IF_pred': pred, 'Cycle_Normal': df["Cycle_Normal"]})
    anomalies_df = df[pred == -1].copy()
    anomalies_count = len(anomalies_df)

    col_if_1, col_if_2 = st.columns(2)

    with col_if_1:
        st.metric(label="Nombre d'anomalies d√©tect√©es", value=anomalies_count)
        st.markdown("#### Tableau X (Caract√©ristiques d'entr√©e)")
        st.dataframe(X.head(5))

    with col_if_2:
        st.markdown("#### Matrice de Confusion (R√©el vs Pr√©dit par IF)")
        confusion = pd.crosstab(temp["Cycle_Normal"], temp["IF_pred"], rownames=['R√©el (Cycle_Normal)'],
                                colnames=['Pr√©dit (IF)'])
        st.dataframe(confusion)

        # Calcul des m√©triques pour la conclusion
        VN = confusion.loc[0, -1] if -1 in confusion.columns and 0 in confusion.index else 0
        FN = confusion.loc[0, 1] if 1 in confusion.columns and 0 in confusion.index else 0
        FP = confusion.loc[1, -1] if -1 in confusion.columns and 1 in confusion.index else 0

    st.markdown("#### Conclusion de l'√©valuation :")
    st.success(f"**D√©faillances bien d√©tect√©es (Vrais N√©gatifs) : {VN}** sur {failed_cycles} d√©faillances r√©elles.")
    st.warning(f"**D√©faillances manqu√©es (Faux N√©gatifs) : {FN}** cycle d√©faillant a √©t√© vu comme normal.")
    st.info(f"**Faux Positifs (Normal vu comme d√©faillant) : {FP}** cycle normal a √©t√© vu comme d√©faillant.")

    st.markdown("---")

    st.markdown("#### Lignes class√©es comme Anomalies (Pr√©dit = -1)")
    if anomalies_count > 0:
        st.dataframe(anomalies_df)
    else:
        st.markdown("Aucune anomalie d√©tect√©e avec ce taux de contamination.")


def section_arbre_decision(df):
    """Contient toutes les informations pour la section 3 : Arbre de D√©cision."""

    st.markdown("### Apprentissage Supervis√© : D√©finir les Seuils de D√©faillance")
    st.markdown("L'objectif est d'identifier les param√®tres qui impactent le fonctionnement du robot presseur.")

    # -------------------------------------------------------------------------
    # 1. Afficher le tableau ¬´ Robot ¬ª
    # -------------------------------------------------------------------------
    with st.expander("1. Afficher le tableau 'Robot' complet"):
        st.dataframe(df)
        st.success("Le tableau complet (avec la variable cible 'Cycle_Normal') est affich√©.")

    # D√©terminer les entr√©es et les sorties (fait une seule fois pour les √©tapes suivantes)
    X_tree = df.drop(columns=["Cycle_Normal"])
    y_tree = df["Cycle_Normal"]

    # Entra√Ænement du mod√®le (fait une seule fois pour les √©tapes suivantes)
    tree, X_train, X_test, y_train, y_test = train_decision_tree(X_tree, y_tree)

    # -------------------------------------------------------------------------
    # 2. D√©terminer les entr√©es et les sorties
    # -------------------------------------------------------------------------
    with st.expander("2. D√©terminer les entr√©es (X) et la sortie (y)"):
        st.markdown("#### Entr√©es (X) : Caract√©ristiques d'impact")
        st.text(", ".join(X_tree.columns.tolist()))
        st.info(f"Dimensions : {X_tree.shape}")

        st.markdown("#### Sortie (y) : √âtat du cycle")
        st.text("Cycle_Normal (1 = Normal, 0 = D√©faillant)")
        st.info(f"Dimensions : {y_tree.shape}")

    # -------------------------------------------------------------------------
    # 3. Importer le mod√®le et entrainer le (D√©j√† fait par la fonction ci-dessus)
    # 4. Calculer le nombre de n≈ìud
    # -------------------------------------------------------------------------
    with st.expander("3. Entra√Æner le mod√®le et calculer les n≈ìuds"):
        score_train = tree.score(X_train, y_train)
        score_test = tree.score(X_test, y_test)

        st.metric(label="Nombre de n≈ìuds dans l'arbre", value=tree.tree_.node_count)
        st.metric(label="Profondeur de l'arbre", value=tree.get_depth())

        st.markdown("#### Performance du Mod√®le")
        st.metric(label="Pr√©cision sur l'entra√Ænement (Train)", value=f"{score_train * 100:.2f}%")
        st.metric(label="Pr√©cision sur le test (Test)", value=f"{score_test * 100:.2f}%")
        st.info("L'entra√Ænement a √©t√© effectu√© sur 70% des donn√©es (X_train).")

    # -------------------------------------------------------------------------
    # 5. Afficher l‚Äôarbre
    # -------------------------------------------------------------------------
    with st.expander("5. Afficher l'Arbre de D√©cision (pour interpr√©tation)", expanded=True):
        st.markdown("L'arbre montre les r√®gles apprises pour s√©parer les classes.")

        fig_tree = plt.figure(figsize=(15, 10))
        plot_tree(tree,
                  feature_names=X_tree.columns.tolist(),
                  class_names=["D√©faillant", "Normal"],
                  filled=True,
                  rounded=True,
                  fontsize=8)
        plt.title("Arbre de d√©cision - D√©tection de d√©faillances", fontsize=14)
        st.pyplot(fig_tree)

    # -------------------------------------------------------------------------
    # 6. Commenter ce r√©sultat
    # -------------------------------------------------------------------------
    with st.expander("6. Commentaire sur les r√©sultats de l'arbre"):
        st.markdown("#### Interpr√©tation des Scores :")
        st.markdown(
            f"- **Pr√©cision Train ({score_train * 100:.2f}%)** : L'arbre est presque parfait sur les donn√©es qu'il a vues. Une valeur de 100% (ou proche) est fr√©quente avec `max_depth=None`.")
        st.markdown(
            f"- **Pr√©cision Test ({score_test * 100:.2f}%)** : Le score sur l'ensemble de test, qui simule de nouvelles donn√©es, est tr√®s √©lev√©. Cela confirme que l'arbre a trouv√© des r√®gles de s√©paration **robustes**.")
        st.markdown(
            "- **Conclusion** : Le mod√®le est tr√®s performant et n'a pas montr√© de surapprentissage significatif, car la performance se maintient bien sur les donn√©es de test. L'arbre utilise tr√®s peu de n≈ìuds (Prof. 2) pour atteindre ce niveau de pr√©cision, ce qui le rend **tr√®s interpr√©table**.")

    # -------------------------------------------------------------------------
    # 7. Que signifie X[0], X[1], X[2] ? Pourquoi il y a que ces crit√®res ?
    # -------------------------------------------------------------------------
    with st.expander("7. Analyse des crit√®res d√©cisifs (X[0], X[1], X[2])"):
        # Mapping des indices vers les noms de colonnes
        column_names = X_tree.columns.tolist()

        st.markdown(f"**X[0]** : `{column_names[0]}` (Temps_Cycle)")
        st.markdown(f"**X[1]** : `{column_names[1]}` (Effort_Arriere)")
        st.markdown(f"**X[2]** : `{column_names[2]}` (Effort_Avant)")

        st.markdown("#### Pourquoi seulement ces crit√®res ?")
        st.markdown(
            "1. **S√©lection Automatique** : L'algorithme de l'Arbre de D√©cision s√©lectionne les variables qui r√©duisent le plus l'impuret√© (Gini/Entropie) √† chaque n≈ìud.")
        st.markdown(
            "2. **Suffisance** : Si un petit sous-ensemble de variables (ici X[0], X[1], X[2]) permet d√©j√† de s√©parer parfaitement ou presque les cycles d√©faillants des cycles normaux, **les autres variables ne sont pas utilis√©es**.")
        st.markdown(
            "3. **Impact** : Cela signifie que le **temps de cycle**, l'**effort arri√®re**, et l'**effort avant** sont les param√®tres ayant le plus grand impact sur la d√©faillance du robot.")

    # -------------------------------------------------------------------------
    # 8. Si j‚Äôenrichi le fichier de donn√©es, le r√©sultat changera-t-il ?
    # -------------------------------------------------------------------------
    with st.expander("8. Impact de l'enrichissement des donn√©es"):
        st.markdown("#### Le r√©sultat changera-t-il ?")
        st.success("‚úÖ **OUI**, le r√©sultat changera tr√®s probablement.")
        st.markdown("#### Explication :")
        st.markdown(
            "1. **Mod√®le Non Statique** : L'arbre de d√©cision est un mod√®le qui **apprend des donn√©es d'entra√Ænement**. Si de nouvelles donn√©es sont ajout√©es (enrichissement), l'entra√Ænement (`tree.fit()`) se fera sur un nouvel ensemble.")
        st.markdown(
            "2. **Adaptation des Seuils** : L'ajout de nouvelles valeurs (surtout des cas limites ou de nouveaux cas de d√©faillance) peut obliger l'arbre √† **ajuster les seuils de d√©cision** (ex: passer de `Temps_Cycle <= 14.5` √† `Temps_Cycle <= 14.2`).")
        st.markdown(
            "3. **Interpr√©tabilit√©** : De nouvelles donn√©es pourraient potentiellement introduire de nouveaux crit√®res d√©cisifs, ou rendre les crit√®res actuels moins pertinents, changeant ainsi l'interpr√©tation finale.")

    st.markdown("---")


def run_analysis(df):
    """Structure de l'application Streamlit avec des onglets."""

    # Cr√©ation des onglets
    tab1, tab2, tab3 = st.tabs([
        "üìä 1. Exploration des Donn√©es",
        "üå≤ 2. Isolation Forest (Non Supervis√©)",
        "üå≥ 3. Arbre de D√©cision (Supervis√©)"
    ])

    with tab1:
        st.header("üìä 1. Exploration des Donn√©es")
        section_exploration(df)

    with tab2:
        st.header("üå≤ 2. Apprentissage Non Supervis√© : Isolation Forest")
        section_isolation_forest(df)

    with tab3:
        st.header("üå≥ 3. Apprentissage Supervis√© : Arbre de D√©cision")
        section_arbre_decision(df)


# =============================================================================
# STRUCTURE DE L'INTERFACE STREAMLIT
# =============================================================================

def main():
    st.set_page_config(layout="wide", page_title="Analyse Robot - D√©faillances")

    st.title("ü§ñ Analyse des D√©faillances d'un Robot Industriel")
    st.markdown(
        "Interface d'analyse comparative structur√©e en trois √©tapes cl√©s : Exploration, D√©tection d'Anomalies (IF) et Classification (Arbre).")

    data = load_data()

    if data is not None:
        run_analysis(data)


if __name__ == "__main__":
    main()